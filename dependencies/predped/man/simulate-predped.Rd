% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simulate.R
\name{simulate,predped-method}
\alias{simulate,predped-method}
\title{Simulate the M4MA}
\usage{
\S4method{simulate}{predped}(
  object,
  max_agents = 20,
  iterations = 1800,
  add_agent_after = function(x) rnorm(x, 60, 15),
  standing_start = 0.1,
  initial_agents = NULL,
  initial_condition = NULL,
  initial_number_agents = NULL,
  goal_number = function(x) rnorm(x, 10, 2),
  goal_duration = function(x) rnorm(x, 10, 2),
  precompute_goal_paths = FALSE,
  sort_goals = TRUE,
  precomputed_goals = NULL,
  middle_edge = FALSE,
  space_between = 1.25,
  time_step = 0.5,
  precompute_edges = TRUE,
  many_nodes = precompute_edges,
  individual_differences = FALSE,
  group_size = matrix(1, nrow = 1, ncol = 2),
  fx = function(x) x,
  ...
)
}
\arguments{
\item{object}{Object of the \code{\link[predped]{predped-class}}.}

\item{max_agents}{Numeric, vector, or function that defines the maximal number
of agents at each iteration in the simulation. If a vector, the maximal number
of agents will be different at each iteration, allowing users to specify
peak and off-peak scenarios. It's exact value is handled by
\code{\link[predped]{determine_values}}. Defaults to \code{20}.}

\item{iterations}{Numeric denoting the number of iterations to run the
simulation for. Defaults to \code{1800}, which corresponds to 15 minutes of
simulation.}

\item{add_agent_after}{Numeric, vector, or function that defines the maximal number
of agents at each iteration in the simulation. It's exact value is handled by
\code{\link[predped]{determine_values}}. Defaults to
\code{\(n) rnorm(n, 60, 15)} or someone walking in every 30 seconds on
average.}

\item{standing_start}{Numeric denoting the factor of their preferred speed
that agents move when they just came from standing still. Defaults to
\code{0.1}.}

\item{initial_agents}{List of objects of the \code{\link[predped]{agent-class}}
with which to start the simulation. Defaults to \code{NULL}, meaning the
simulation starts with an empty room.}

\item{initial_condition}{Object of the \code{\link[predped]{state-class}}
containing the initial state at which to start the simulation. Defaults to
\code{NULL}, meaning the simulation starts with an empty room. Ignored when
\code{initial_agents} or \code{initial_number_agents} is provided.}

\item{initial_number_agents}{Numeric denoting the number of agents that
the simulation should start out with. Defaults to \code{NULL}, meaning the
simulation should start with no agents in the room. Ignored if
\code{initial_agents} is provided.}

\item{goal_number}{Numeric, vector, or function that defines the number of
goals the agents should accomplish. It's exact value is handled by
\code{\link[predped]{determine_values}}. Defaults to \code{\(n) rnorm(n, 10, 2)}.}

\item{goal_duration}{Numeric, vector, or function that defines the duration of
the goals of the agents. Defaults to \code{\(n) rnorm(n, 10, 2)}.}

\item{precompute_goal_paths}{Logical denoting whether to run the
\code{\link[predped]{find_path-method}} for each of the generated goals
beforehand. Assumes that the agent does all of the goals in the order of the
goal stack. Defaults to \code{FALSE}.}

\item{sort_goals}{Logical denoting whether to order the goal stack in a logical
way. Currently implemented in the following way. First, we select the first
goal as being the one that is closest by the starting position provided in
the argument \code{starting_position}. Then, we define each of the next goals
as being the one that is closest to the position of the previous goal.
Defaults to \code{TRUE}.}

\item{precomputed_goals}{List of goal stacks from which the agent can be
assigned one. Defaults to \code{NULL}, triggering the creation of goal stacks
in the simulation.}

\item{middle_edge}{Logical denoting whether to sample the goals from the
middle of the edge of the objects in the \code{link[predped]{background-class}}
(\code{TRUE}) or to allow the goal locations to fall on all points on these
edges (\code{FALSE}). Defaults to \code{FALSE}.}

\item{space_between}{Numeric denoting the multiplier for the space to leave
between the circumference of the object and the nodes created under the hood
(see \code{\link[predped]{add_nodes}}). Is multiplied by the agent's radius
to determine the actual space to leave between object and node. Defaults to
\code{2.5}.}

\item{time_step}{Numeric denoting the number of seconds each discrete step in
time should mimic. Defaults to \code{0.5}, or half a second.}

\item{precompute_edges}{Logical denoting whether to precompute the path points
on which agents can move. Defaults to \code{TRUE}, triggering the creation
of edges through the \code{\link[predped]{compute_edges}} function.}

\item{many_nodes}{Logical denoting whether to use the minimal amount of path
points necessary for the edges (\code{FALSE}) or to use many more \code{TRUE}.
Defaults to \code{TRUE} if \code{precompute_edges = TRUE}, and otherwise
defaults to \code{FALSE}. See \code{\link[predped]{create_edges}} for full
disclosure on the effect of this logical.}

\item{individual_differences}{Logical denoting whether to use the standard
deviations in the parameter list to create some variation in the parameters.
Defaults to \code{FALSE}.}

\item{group_size}{Numeric matrix with two columns where the first column
denotes the number of people in a social group and the second column the
probability with which such a group is added to the simulation. Defaults to
a 100\% probability that individuals are added to the simulation (i.e., no
social groups).}

\item{fx}{Function that takes in and returns an object of the
\code{\link[predped]{state-class}}. This will be executed at the beginning of each
iteration and allows users some flexibility in their simulations. For example
useful when simulating evacuations (giving everyone "goal exit") or trying
to guide behavior in any other way. Defaults to "\(x) x", meaning the state
remains unaltered.}

\item{...}{Arguments passed on to the \code{\link[predped]{simulate,state-method}}
function.}

\item{plot_live}{Logical denoting whether to plot each iteration while the
simulation is going on. Defaults to \code{FALSE}.}

\item{plot_time}{Numeric denoting the amount of time (in seconds) to wait
between iterations, i.e., the time between updating the plot. Defaults to
\code{0.2}.}
}
\value{
List of objects of the \code{\link{state-class}} containing the
result of the simulation.
}
\description{
This function allows users to simulate data from their specified
\code{\link[predped]{predped-class}}.
}
\details{
Heavily depends on \code{\link[predped]{simulate,state-method}} and
\code{\link[predped]{update}}.

The arguments that can be used to influence the simulation behavior might
be overwhelming, which is why we include a small categorization of the
arguments in this sections. Roughly speaking, this function has multiple
arguments that influence a same aspect of the simulation. These are the
following (note that here all arguments are provided; some of these may
only appear in the documentation of \code{\link[predped]{simulate,state-method}}).

Arguments that directly influence the general characteristics of the
simulation and the model itself.
\itemize{
    \item{\code{max_agent}:}{How many agents that can be in the room.}
    \item{\code{iterations}:}{How long the simulation should last.}
    \item{\code{add_agent_after}:}{How many iterations to leave between
                                   each agent entering the room.}
    \item{\code{time_step}:}{How much time passes after each iteration.}
    \item{\code{velocities}:}{To which extent an agent can change their speed
                              from one iteration to the next.}
    \item{\code{orientations}:}{To which extent an agent can change their
                                direction from one iteration to the next.}
    \item{\code{stay_stopped}:}{Whether agents predict currently immobile
                                pedestrians to remain immobile.}
}

Arguments that influence general characteristics of the agents.
\itemize{
    \item{\code{individual_differences}:}{Whether agents should have
                                          continuous individual differences.}
    \item{\code{standing_start}:}{How fast agents are after standing still.}
}

Arguments controlling whether an initial condition should be used.
\itemize{
    \item{\code{initial_agents}:}{An initial list of agents.}
    \item{\code{initial_number_agents}:}{An initial number of agents with
                                         which you want to start the
                                         simulation.}
    \item{\code{initial_condition}:}{An initial state.}
}
Preferably, only one is used at a time.

Arguments controlling the goals, which can be easily traced back to the
\code{\link[predped]{goal_stack}} function.
\itemize{
    \item{\code{goal_number}:}{The number of goals the agents should have.}
    \item{\code{goal_duration}:}{How long each goal should take.}
    \item{\code{precompute_goal_paths}:}{Whether the paths to the goals should
                                         be precomputed.}
    \item{\code{sort_goals}:}{Whether to sort the goals based on distance.
                              Corresponds to the \code{sort} argument in
                              \code{\link[predped]{goal_stack}}.}
    \item{\code{precomputed_goals}:}{List of goal stacks that already exist
                                     and which should be assigned to the
                                     agents.}
}

Arguments controlling how path points and edges are handled.
\itemize{
    \item{\code{precomputed_edges}:}{List containing nodes and edges.}
    \item{\code{many_nodes}:}{Whether to have many or few path points.}
    \item{\code{space_between}:}{Space to leave between objects and nodes.}
    \item{\code{close_enough}:}{How close a pedestrian should be before they
                                can (a) interact with a goal or (b) start
                                planning to go to another path point.}
}

Arguments that handle feedback during the simulation.
\itemize{
    \item{\code{plot_live}:}{Whether to make these plots.}
    \item{\code{plot_time}:}{How much time to leave between the plotting of
                             each state.}
    \item{\code{report}:}{Whether to report whenever agents are reorienting.}
}
}
\examples{
# Create a setting in which to simulate. Note that this setting also serves
# as an example of one-directional flow, which can be seen if you let the
# simulation run a bit longer.
my_background <- background(shape = rectangle(center = c(0, 0),
                                              size = c(2, 2)),
                            objects = list(rectangle(center = c(0, 0),
                                                     size = c(1, 1))),
                            limited_access = list(segment(from = c(-1, 0.5),
                                                          to = c(-0.5, 0.5)),
                                                  segment(from = c(0.5, 1),
                                                          to = c(0.5, 0.5)),
                                                  segment(from = c(1, -0.5),
                                                          to = c(0.5, -0.5)),
                                                  segment(from = c(-0.5, -1),
                                                          to = c(-0.5, -0.5))))

# Create a model from which to simulate
my_model <- predped(setting = my_background,
                    archetypes = c("BaselineEuropean"))

# Do the simulation for maximally 2 agents
trace <- simulate(my_model,
                  max_agents = 2,
                  iterations = 10,
                  add_agent_after = 5)

# Check some interesting statistics, such as the length of the trace and the
# number of agents in the room.
length(trace)
sapply(trace, \(x) length(x@agents))

# If you wish to plot the trace, you can simply use the plot function.
plt <- plot(trace)
plt[[1]]

}
\seealso{
\code{\link[predped]{simulate,state-method}},
\code{\link[predped]{update}}
}
